{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Novel Cascade Binary Tagging Framework for Relational Triple Extraction ACL 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1前言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1,1课程回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='imgs/overall_for_code.png' width=\"800\" height=\"800\" align=\"bottom\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 模型结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/casrel.png\"  width=\"600\" height=\"600\" align=\"bottom\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 代码结构展示\n",
    "<img src=\"./imgs/directory.jpg\"  width=\"300\" height=\"300\" align=\"bottom\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 准备工作\n",
    "### 2.1项目环境配置\n",
    "\n",
    "* Python3.8\n",
    "* jupyter notebook\n",
    "* torch            1.6.0+cu10.2\n",
    "* numpy            1.18.5\n",
    "* transformers       3.4.0\n",
    "\n",
    "代码运行环境建议使用Visual Studio Code(VScode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 数据集下载\n",
    "NYT数据集下载地址：https://drive.google.com/file/d/10f24s9gM7NdyO3z5OqQxJgYud4NnCJg3/view <br> \n",
    "WEBNLG数据集下载地址：https://drive.google.com/file/d/1zISxYa-8ROe2Zv8iRc82jY9QsQrfY1Vj/view <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 项目代码结构（VScode中演示）\n",
    "\n",
    ">1）是什么？\n",
    "\n",
    "　　我们首先会在VScode环境中让代码跑一下，直观感受到项目的训练，并展示前向推断的输出，让大家看到模型的效果。\n",
    ">2）怎么构成的？\n",
    "\n",
    "　　然后介绍项目代码的构成，介绍项目有哪些文件夹，包含哪些文件，这些文件构成了什么功能模块如：数据预处理模块，模型设计模块，损失函数模块，推断与评估模块。\n",
    ">3）小结\n",
    "\n",
    "　　在主文件中在过一下启动训练的流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 算法模块及细节（jupyter和VScode中演示）\n",
    "\n",
    "　　在jupyter notebook中细致地讲解每一个模块。\n",
    "  \n",
    "　　以实现模块功能为目的，来讲解每个函数的执行流程，呈现中间数据，方便同学们理解学习。\n",
    "  \n",
    "　　内容分为以下几个模块：**超参数设置，数据读取，数据预处理，模型训练，模型评价**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 超参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "import config\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_name', type=str, default='Casrel', help='name of the model')\n",
    "parser.add_argument('--lr', type=float, default=1e-5)\n",
    "parser.add_argument('--multi_gpu', type=bool, default=False)\n",
    "parser.add_argument('--dataset', type=str, default='NYT')\n",
    "parser.add_argument('--batch_size', type=int, default=6)\n",
    "parser.add_argument('--max_epoch', type=int, default=15) #300\n",
    "parser.add_argument('--test_epoch', type=int, default=1)\n",
    "parser.add_argument('--train_prefix', type=str, default='train_triples')\n",
    "parser.add_argument('--dev_prefix', type=str, default='dev_triples')\n",
    "parser.add_argument('--test_prefix', type=str, default='test_triples')\n",
    "parser.add_argument('--max_len', type=int, default=150)\n",
    "parser.add_argument('--rel_num', type=int, default=44)\n",
    "parser.add_argument('--period', type=int, default=50)\n",
    "parser.add_argument('--debug', type=bool, default=False)\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "con = config.Config(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_config(con):\n",
    "    for key in con.__dict__:\n",
    "        print(key, end=' = ')\n",
    "        print(con.__dict__[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args = Namespace(batch_size=6, dataset='NYT', debug=False, dev_prefix='dev_triples', lr=1e-05, max_epoch=15, max_len=150, model_name='Casrel', multi_gpu=False, period=50, rel_num=44, test_epoch=1, test_prefix='test_triples', train_prefix='train_triples')\n",
      "multi_gpu = False\n",
      "learning_rate = 1e-05\n",
      "batch_size = 6\n",
      "max_epoch = 15\n",
      "max_len = 150\n",
      "rel_num = 44\n",
      "dataset = NYT\n",
      "root = /home/niuhao/project/RE/CasRel_2020\n",
      "data_path = /home/niuhao/project/RE/CasRel_2020/data/NYT\n",
      "checkpoint_dir = /home/niuhao/project/RE/CasRel_2020/checkpoint/NYT\n",
      "log_dir = /home/niuhao/project/RE/CasRel_2020/log/NYT\n",
      "result_dir = /home/niuhao/project/RE/CasRel_2020/result/NYT\n",
      "train_prefix = train_triples\n",
      "dev_prefix = dev_triples\n",
      "test_prefix = test_triples\n",
      "model_save_name = Casrel_DATASET_NYT_LR_1e-05_BS_6\n",
      "log_save_name = LOG_Casrel_DATASET_NYT_LR_1e-05_BS_6\n",
      "result_save_name = RESULT_Casrel_DATASET_NYT_LR_1e-05_BS_6.json\n",
      "period = 50\n",
      "test_epoch = 1\n",
      "debug = False\n"
     ]
    }
   ],
   "source": [
    "print_config(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open(os.path.join(con.data_path, con.train_prefix + '.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel2id = json.load(open(os.path.join(con.data_path, 'rel2id.json')))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56195"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Massachusetts ASTON MAGNA Great Barrington ; also at Bard College , Annandale-on-Hudson , N.Y. , July 1-Aug .',\n",
       " 'triple_list': [['Annandale-on-Hudson',\n",
       "   '/location/location/contains',\n",
       "   'College']]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'North Carolina EASTERN MUSIC FESTIVAL Greensboro , June 25-July 30 .'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = train_data[1]['text']\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'North Carolina EASTERN MUSIC FESTIVAL Greensboro , June 25-July 30 .'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' '.join(text.split())\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['north',\n",
       " 'carolina',\n",
       " 'eastern',\n",
       " 'music',\n",
       " 'festival',\n",
       " 'greensboro',\n",
       " ',',\n",
       " 'june',\n",
       " '25',\n",
       " '-',\n",
       " 'july',\n",
       " '30',\n",
       " '.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2ro_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Weiner', '/people/person/place_lived', 'Queens'],\n",
       " ['Weiner', '/people/person/place_lived', 'Brooklyn']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[6]['triple_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Carolina', '/location/location/contains', 'Greensboro']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triple = train_data[1]['triple_list'][0]\n",
    "triple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carolina']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(triple[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['carolina'], '/location/location/contains', ['greensboro'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triple = (tokenizer.tokenize(triple[0]), triple[1], tokenizer.tokenize(triple[2]))\n",
    "triple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "source = tokens\n",
    "target = triple[0]\n",
    "target_len = len(target)\n",
    "for i in range(len(source)):\n",
    "    if source[i: i + target_len] == target:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_head_idx(source, target):\n",
    "    target_len = len(target)\n",
    "    for i in range(len(source)):\n",
    "        if source[i: i + target_len] == target:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_head_idx = find_head_idx(tokens, triple[0])\n",
    "print(sub_head_idx)\n",
    "obj_head_idx = find_head_idx(tokens, triple[2])\n",
    "obj_head_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = (sub_head_idx, sub_head_idx + len(triple[0]) - 1)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 1): []}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if sub not in s2ro_map:\n",
    "    s2ro_map[sub] = []\n",
    "s2ro_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 1): [(5, 5, 22)]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2ro_map[sub].append((obj_head_idx, obj_head_idx + len(triple[2]) - 1, rel2id[triple[1]]))\n",
    "s2ro_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2167,\n",
       " 3792,\n",
       " 2789,\n",
       " 2189,\n",
       " 2782,\n",
       " 27905,\n",
       " 1010,\n",
       " 2238,\n",
       " 2423,\n",
       " 1011,\n",
       " 2251,\n",
       " 2382,\n",
       " 1012,\n",
       " 102]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = tokenizer.encode(text)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101,  2167,  3792,  2789,  2189,  2782, 27905,  1010,  2238,\n",
       "        2423,  1011,  2251,  2382,  1012,   102])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = np.array(token_ids)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_len = len(tokens)\n",
    "text_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_heads, sub_tails = np.zeros(text_len), np.zeros(text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 1): [(5, 5, 22)]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2ro_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [s for s in s2ro_map][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_heads[s[0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_tails[s[1]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_heads, obj_tails = np.zeros((text_len, con.rel_num)), np.zeros((text_len, con.rel_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.rel_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 44)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_heads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_head_idx, sub_tail_idx = choice(list(s2ro_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_head_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ro in s2ro_map.get((sub_head_idx, sub_tail_idx), []):\n",
    "    obj_heads[ro[0]][ro[2]] = 1\n",
    "    obj_tails[ro[1]][ro[2]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_tails[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 将上述功能构建为类\n",
    "* 将相似类型的功能整合到一个类里，使代码结构更清晰，并且方面以后调佣，且有利于debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.4.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import data_loader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Casrel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Casrel, self).__init__()\n",
    "        self.config = config\n",
    "        self.bert_dim = 768\n",
    "        self.bert_encoder = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.sub_heads_linear = nn.Linear(self.bert_dim, 1)\n",
    "        self.sub_tails_linear = nn.Linear(self.bert_dim, 1)\n",
    "        self.obj_heads_linear = nn.Linear(self.bert_dim, self.config.rel_num)\n",
    "        self.obj_tails_linear = nn.Linear(self.bert_dim, self.config.rel_num)\n",
    "\n",
    "    def get_objs_for_specific_sub(self, sub_head_mapping, sub_tail_mapping, encoded_text):\n",
    "        # [batch_size, 1, bert_dim]\n",
    "        sub_head = torch.matmul(sub_head_mapping, encoded_text)\n",
    "        # [batch_size, 1, bert_dim]\n",
    "        sub_tail = torch.matmul(sub_tail_mapping, encoded_text)\n",
    "        # [batch_size, 1, bert_dim]\n",
    "        sub = (sub_head + sub_tail) / 2\n",
    "        # [batch_size, seq_len, bert_dim]\n",
    "        encoded_text = encoded_text + sub\n",
    "        # [batch_size, seq_len, rel_num]\n",
    "        pred_obj_heads = self.obj_heads_linear(encoded_text)\n",
    "        pred_obj_heads = torch.sigmoid(pred_obj_heads)\n",
    "        # [batch_size, seq_len, rel_num]\n",
    "        pred_obj_tails = self.obj_tails_linear(encoded_text)\n",
    "        pred_obj_tails = torch.sigmoid(pred_obj_tails)\n",
    "        return pred_obj_heads, pred_obj_tails\n",
    "\n",
    "    def get_encoded_text(self, token_ids, mask):\n",
    "        # [batch_size, seq_len, bert_dim(768)]\n",
    "        encoded_text = self.bert_encoder(token_ids, attention_mask=mask)[0]\n",
    "        return encoded_text\n",
    "\n",
    "    def get_subs(self, encoded_text):\n",
    "        # [batch_size, seq_len, 1]\n",
    "        pred_sub_heads = self.sub_heads_linear(encoded_text)\n",
    "        pred_sub_heads = torch.sigmoid(pred_sub_heads)\n",
    "        # [batch_size, seq_len, 1]\n",
    "        pred_sub_tails = self.sub_tails_linear(encoded_text)\n",
    "        pred_sub_tails = torch.sigmoid(pred_sub_tails)\n",
    "        return pred_sub_heads, pred_sub_tails\n",
    "\n",
    "    def forward(self, data):\n",
    "        # [batch_size, seq_len]\n",
    "        token_ids = data['token_ids']\n",
    "        # [batch_size, seq_len]\n",
    "        mask = data['mask']\n",
    "        # [batch_size, seq_len, bert_dim(768)]\n",
    "        encoded_text = self.get_encoded_text(token_ids, mask)\n",
    "        # [batch_size, seq_len, 1]\n",
    "        pred_sub_heads, pred_sub_tails = self.get_subs(encoded_text)\n",
    "        # [batch_size, 1, seq_len]\n",
    "        sub_head_mapping = data['sub_head'].unsqueeze(1)\n",
    "        # [batch_size, 1, seq_len]\n",
    "        sub_tail_mapping = data['sub_tail'].unsqueeze(1)\n",
    "        # [batch_size, seq_len, rel_num]\n",
    "        pred_obj_heads, pred_obj_tails = self.get_objs_for_specific_sub(sub_head_mapping, sub_tail_mapping, encoded_text)\n",
    "        return pred_sub_heads, pred_sub_tails, pred_obj_heads, pred_obj_tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Casrel(\n",
       "  (bert_encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (sub_heads_linear): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (sub_tails_linear): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (obj_heads_linear): Linear(in_features=768, out_features=44, bias=True)\n",
       "  (obj_tails_linear): Linear(in_features=768, out_features=44, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_model = Casrel(con)\n",
    "ori_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, ori_model.parameters()), lr=con.learning_rate)\n",
    "\n",
    "# whether use multi GPU\n",
    "if con.multi_gpu:\n",
    "    model = nn.DataParallel(ori_model)\n",
    "else:\n",
    "    model = ori_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function\n",
    "def loss(gold, pred, mask):\n",
    "    pred = pred.squeeze(-1)\n",
    "    los = F.binary_cross_entropy(pred, gold, reduction='none')\n",
    "    if los.shape != mask.shape:\n",
    "        mask = mask.unsqueeze(-1)\n",
    "    los = torch.sum(los * mask) / torch.sum(mask)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the checkpoint dir\n",
    "if not os.path.exists(con.checkpoint_dir):\n",
    "    os.mkdir(con.checkpoint_dir)\n",
    "\n",
    "# check the log dir\n",
    "if not os.path.exists(con.log_dir):\n",
    "    os.mkdir(con.log_dir)\n",
    "\n",
    "# get the data loader\n",
    "train_data_loader = data_loader.get_loader(con, prefix=con.train_prefix)\n",
    "dev_data_loader = data_loader.get_loader(con, prefix=con.dev_prefix, is_test=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "global_step = 0\n",
    "loss_sum = 0\n",
    "\n",
    "best_f1_score = 0\n",
    "best_precision = 0\n",
    "best_recall = 0\n",
    "\n",
    "best_epoch = 0\n",
    "init_time = time.time()\n",
    "start_time = time.time()\n",
    "\n",
    "# the training loop\n",
    "for epoch in range(self.config.max_epoch):\n",
    "    train_data_prefetcher = data_loader.DataPreFetcher(train_data_loader)\n",
    "    data = train_data_prefetcher.next()\n",
    "    while data is not None:\n",
    "        pred_sub_heads, pred_sub_tails, pred_obj_heads, pred_obj_tails = model(data)\n",
    "\n",
    "        sub_heads_loss = loss(data['sub_heads'], pred_sub_heads, data['mask'])\n",
    "        sub_tails_loss = loss(data['sub_tails'], pred_sub_tails, data['mask'])\n",
    "        obj_heads_loss = loss(data['obj_heads'], pred_obj_heads, data['mask'])\n",
    "        obj_tails_loss = loss(data['obj_tails'], pred_obj_tails, data['mask'])\n",
    "        total_loss = (sub_heads_loss + sub_tails_loss) + (obj_heads_loss + obj_tails_loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        global_step += 1\n",
    "        loss_sum += total_loss.item()\n",
    "\n",
    "        if global_step % self.config.period == 0:\n",
    "            cur_loss = loss_sum / self.config.period\n",
    "            elapsed = time.time() - start_time\n",
    "            self.logging(\"epoch: {:3d}, step: {:4d}, speed: {:5.2f}ms/b, train loss: {:5.3f}\".\n",
    "                         format(epoch, global_step, elapsed * 1000 / self.config.period, cur_loss))\n",
    "            loss_sum = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "        data = train_data_prefetcher.next()\n",
    "\n",
    "    if (epoch + 1) % self.config.test_epoch == 0:\n",
    "        eval_start_time = time.time()\n",
    "        model.eval()\n",
    "        # call the test function\n",
    "        precision, recall, f1_score = self.test(dev_data_loader, model)\n",
    "        model.train()\n",
    "        self.logging('epoch {:3d}, eval time: {:5.2f}s, f1: {:4.2f}, precision: {:4.2f}, recall: {:4.2f}'.\n",
    "                     format(epoch, time.time() - eval_start_time, f1_score, precision, recall))\n",
    "\n",
    "        if f1_score > best_f1_score:\n",
    "            best_f1_score = f1_score\n",
    "            best_epoch = epoch\n",
    "            best_precision = precision\n",
    "            best_recall = recall\n",
    "            self.logging(\"saving the model, epoch: {:3d}, best f1: {:4.2f}, precision: {:4.2f}, recall: {:4.2f}\".\n",
    "                         format(best_epoch, best_f1_score, precision, recall))\n",
    "            # save the best model\n",
    "            path = os.path.join(self.config.checkpoint_dir, self.config.model_save_name)\n",
    "            if not self.config.debug:\n",
    "                torch.save(ori_model.state_dict(), path)\n",
    "\n",
    "    # manually release the unused cache\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "self.logging(\"finish training\")\n",
    "self.logging(\"best epoch: {:3d}, best f1: {:4.2f}, precision: {:4.2f}, recall: {:4.2}, total time: {:5.2f}s\".\n",
    "             format(best_epoch, best_f1_score, best_precision, best_recall, time.time() - init_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 模型评价\n",
    "现在假设训练好了一个模型（或者模型训练了一个epoch），我们想看看模型现在的性能，那么就需要对模型进行评价\n",
    "\n",
    "**目录**\n",
    "* 模型预测\n",
    "* 计算评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(self, test_data_loader, model, output=False, h_bar=0.5, t_bar=0.5):\n",
    "\n",
    "    if output:\n",
    "        # check the result dir\n",
    "        if not os.path.exists(self.config.result_dir):\n",
    "            os.mkdir(self.config.result_dir)\n",
    "\n",
    "        path = os.path.join(self.config.result_dir, self.config.result_save_name)\n",
    "\n",
    "        fw = open(path, 'w')\n",
    "\n",
    "    orders = ['subject', 'relation', 'object']\n",
    "\n",
    "    def to_tup(triple_list):\n",
    "        ret = []\n",
    "        for triple in triple_list:\n",
    "            ret.append(tuple(triple))\n",
    "        return ret\n",
    "\n",
    "    test_data_prefetcher = data_loader.DataPreFetcher(test_data_loader)\n",
    "    data = test_data_prefetcher.next()\n",
    "    id2rel = json.load(open(os.path.join(self.config.data_path, 'rel2id.json')))[0]\n",
    "    correct_num, predict_num, gold_num = 0, 0, 0\n",
    "\n",
    "    while data is not None:\n",
    "        with torch.no_grad():\n",
    "            token_ids = data['token_ids']\n",
    "            tokens = data['tokens'][0]\n",
    "            mask = data['mask']\n",
    "            encoded_text = model.get_encoded_text(token_ids, mask)\n",
    "            pred_sub_heads, pred_sub_tails = model.get_subs(encoded_text)\n",
    "            sub_heads, sub_tails = np.where(pred_sub_heads.cpu()[0] > h_bar)[0], np.where(pred_sub_tails.cpu()[0] > t_bar)[0]\n",
    "            subjects = []\n",
    "            for sub_head in sub_heads:\n",
    "                sub_tail = sub_tails[sub_tails >= sub_head]\n",
    "                if len(sub_tail) > 0:\n",
    "                    sub_tail = sub_tail[0]\n",
    "                    subject = tokens[sub_head: sub_tail]\n",
    "                    subjects.append((subject, sub_head, sub_tail))\n",
    "            if subjects:\n",
    "                triple_list = []\n",
    "                # [subject_num, seq_len, bert_dim]\n",
    "                repeated_encoded_text = encoded_text.repeat(len(subjects), 1, 1)\n",
    "                # [subject_num, 1, seq_len]\n",
    "                sub_head_mapping = torch.Tensor(len(subjects), 1, encoded_text.size(1)).zero_()\n",
    "                sub_tail_mapping = torch.Tensor(len(subjects), 1, encoded_text.size(1)).zero_()\n",
    "                for subject_idx, subject in enumerate(subjects):\n",
    "                    sub_head_mapping[subject_idx][0][subject[1]] = 1\n",
    "                    sub_tail_mapping[subject_idx][0][subject[2]] = 1\n",
    "                sub_tail_mapping = sub_tail_mapping.to(repeated_encoded_text)\n",
    "                sub_head_mapping = sub_head_mapping.to(repeated_encoded_text)\n",
    "                pred_obj_heads, pred_obj_tails = model.get_objs_for_specific_sub(sub_head_mapping, sub_tail_mapping, repeated_encoded_text)\n",
    "                for subject_idx, subject in enumerate(subjects):\n",
    "                    sub = subject[0]\n",
    "                    sub = ''.join([i.lstrip(\"##\") for i in sub])\n",
    "                    sub = ' '.join(sub.split('[unused1]'))\n",
    "                    obj_heads, obj_tails = np.where(pred_obj_heads.cpu()[subject_idx] > h_bar), np.where(pred_obj_tails.cpu()[subject_idx] > t_bar)\n",
    "                    for obj_head, rel_head in zip(*obj_heads):\n",
    "                        for obj_tail, rel_tail in zip(*obj_tails):\n",
    "                            if obj_head <= obj_tail and rel_head == rel_tail:\n",
    "                                rel = id2rel[str(int(rel_head))]\n",
    "                                obj = tokens[obj_head: obj_tail]\n",
    "                                obj = ''.join([i.lstrip(\"##\") for i in obj])\n",
    "                                obj = ' '.join(obj.split('[unused1]'))\n",
    "                                triple_list.append((sub, rel, obj))\n",
    "                                break\n",
    "                triple_set = set()\n",
    "                for s, r, o in triple_list:\n",
    "                    triple_set.add((s, r, o))\n",
    "                pred_list = list(triple_set)\n",
    "            else:\n",
    "                pred_list = []\n",
    "            pred_triples = set(pred_list)\n",
    "            gold_triples = set(to_tup(data['triples'][0]))\n",
    "\n",
    "            correct_num += len(pred_triples & gold_triples)\n",
    "            predict_num += len(pred_triples)\n",
    "            gold_num += len(gold_triples)\n",
    "\n",
    "            if output:\n",
    "                result = json.dumps({\n",
    "                    # 'text': ' '.join(tokens),\n",
    "                    'triple_list_gold': [\n",
    "                        dict(zip(orders, triple)) for triple in gold_triples\n",
    "                    ],\n",
    "                    'triple_list_pred': [\n",
    "                        dict(zip(orders, triple)) for triple in pred_triples\n",
    "                    ],\n",
    "                    'new': [\n",
    "                        dict(zip(orders, triple)) for triple in pred_triples - gold_triples\n",
    "                    ],\n",
    "                    'lack': [\n",
    "                        dict(zip(orders, triple)) for triple in gold_triples - pred_triples\n",
    "                    ]\n",
    "                }, ensure_ascii=False)\n",
    "                fw.write(result + '\\n')\n",
    "\n",
    "            data = test_data_prefetcher.next()\n",
    "\n",
    "    print(\"correct_num: {:3d}, predict_num: {:3d}, gold_num: {:3d}\".format(correct_num, predict_num, gold_num))\n",
    "\n",
    "    precision = correct_num / (predict_num + 1e-10)\n",
    "    recall = correct_num / (gold_num + 1e-10)\n",
    "    f1_score = 2 * precision * recall / (precision + recall + 1e-10)\n",
    "    return precision, recall, f1_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTH_1.6",
   "language": "python",
   "name": "pyth_1.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
